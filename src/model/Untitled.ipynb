{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad740ece-0270-4052-bdfe-05042eb83f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_word_tag, load_data, assign_unk\n",
    "from viterbi_tagger import ViterbiTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6197d07a-d565-4155-a379-0bd3ae004e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import string\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6f00581-3a05-4628-ab85-8cc44fab55d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"../../data/WSJ_02-21.pos\"\n",
    "test_path = \"../../data/WSJ_24.pos\"\n",
    "corpus_path = \"../../data/hmm_vocab.txt\"\n",
    "\n",
    "training_corpus = load_data(train_path, False)\n",
    "y = load_data(test_path, False)\n",
    "vocab = load_data(corpus_path, True)\n",
    "\n",
    "prep = []\n",
    "for item in y:\n",
    "    word = item.split('\\t')[0]\n",
    "    if not word in vocab.keys():\n",
    "        prep.append(assign_unk(word))\n",
    "    else:\n",
    "        prep.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8217150-1ac0-4862-b1fa-267fe1e17593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word count = 50000\n",
      "word count = 100000\n",
      "word count = 150000\n",
      "word count = 200000\n",
      "word count = 250000\n",
      "word count = 300000\n",
      "word count = 350000\n",
      "word count = 400000\n",
      "word count = 450000\n",
      "word count = 500000\n",
      "word count = 550000\n",
      "word count = 600000\n",
      "word count = 650000\n",
      "word count = 700000\n",
      "word count = 750000\n",
      "word count = 800000\n",
      "word count = 850000\n",
      "word count = 900000\n",
      "word count = 950000\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.001\n",
    "tagger = ViterbiTagger(0.001)\n",
    "tagger.build_matrices(training_corpus, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73e6b354-e653-41fe-bfc1-a62a455b4b69",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ViterbiTagger' object has no attribute 'A'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m prep = [\u001b[33m'\u001b[39m\u001b[33meconomy\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mwhat\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m--unk--\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mrun\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mtagger\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/personal_projects/sentence_tagging/src/model/viterbi_tagger.py:306\u001b[39m, in \u001b[36mViterbiTagger.tag\u001b[39m\u001b[34m(self, corpus)\u001b[39m\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtag\u001b[39m(\u001b[38;5;28mself\u001b[39m, corpus):\n\u001b[32m    297\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m'''\u001b[39;00m\n\u001b[32m    298\u001b[39m \u001b[33;03m    Performs POS tagging on the given corpus using the internally stored matrices.\u001b[39;00m\n\u001b[32m    299\u001b[39m \u001b[33;03m    \u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    304\u001b[39m \u001b[33;03m        pred: list of predicted POS tags corresponding to the input words\u001b[39;00m\n\u001b[32m    305\u001b[39m \u001b[33;03m    '''\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m306\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mA\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.B \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    307\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mMatrices A and B have not been built. Call build_matrices() first.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    308\u001b[39m     best_probs, best_paths = \u001b[38;5;28mself\u001b[39m.initialize(\n\u001b[32m    309\u001b[39m         \u001b[38;5;28mself\u001b[39m.states,\n\u001b[32m    310\u001b[39m         defaultdict(\u001b[38;5;28mint\u001b[39m, {s: i \u001b[38;5;28;01mfor\u001b[39;00m i, s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.states)}),\n\u001b[32m    311\u001b[39m         \u001b[38;5;28mself\u001b[39m.A, \u001b[38;5;28mself\u001b[39m.B, corpus, \u001b[38;5;28mself\u001b[39m.vocab\n\u001b[32m    312\u001b[39m     )\n",
      "\u001b[31mAttributeError\u001b[39m: 'ViterbiTagger' object has no attribute 'A'"
     ]
    }
   ],
   "source": [
    "prep = ['economy', 'what', '--unk--', 'run']\n",
    "tagger.tag(prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00b02596-0d1f-4a11-930f-ffc7f88b164b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word count = 50000\n",
      "word count = 100000\n",
      "word count = 150000\n",
      "word count = 200000\n",
      "word count = 250000\n",
      "word count = 300000\n",
      "word count = 350000\n",
      "word count = 400000\n",
      "word count = 450000\n",
      "word count = 500000\n",
      "word count = 550000\n",
      "word count = 600000\n",
      "word count = 650000\n",
      "word count = 700000\n",
      "word count = 750000\n",
      "word count = 800000\n",
      "word count = 850000\n",
      "word count = 900000\n",
      "word count = 950000\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 21548 is out of bounds for axis 1 with size 21424",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m A = create_transition_matrix(alpha, tag_counts, transition_counts)\n\u001b[32m      5\u001b[39m B = create_emission_matrix(alpha, tag_counts, emission_counts, \u001b[38;5;28mlist\u001b[39m(vocab))\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m best_probs, best_paths = \u001b[43minitialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtag_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m#tagger = ViterbiTagger(alpha)\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m#tagger.build_matrices(training_data, vocab)\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 94\u001b[39m, in \u001b[36minitialize\u001b[39m\u001b[34m(states, tag_counts, A, B, corpus, vocab)\u001b[39m\n\u001b[32m     92\u001b[39m s_idx = states.index(\u001b[33m\"\u001b[39m\u001b[33m--s--\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_tags):\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m     best_probs[i,\u001b[32m0\u001b[39m] = math.log(A[s_idx, i]) + math.log(\u001b[43mB\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m) \n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m best_probs, best_paths\n",
      "\u001b[31mIndexError\u001b[39m: index 21548 is out of bounds for axis 1 with size 21424"
     ]
    }
   ],
   "source": [
    "alpha = 0.001\n",
    "emission_counts, transition_counts, tag_counts = create_dictionaries(training_data, vocab)\n",
    "states = sorted(tag_counts.keys())\n",
    "A = create_tÂºransition_matrix(alpha, tag_counts, transition_counts)\n",
    "B = create_emission_matrix(alpha, tag_counts, emission_counts, list(vocab))\n",
    "best_probs, best_paths = initialize(states, tag_counts, A, B, prep, vocab)\n",
    "#tagger = ViterbiTagger(alpha)\n",
    "#tagger.build_matrices(training_data, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a746258f-fbc9-440b-a58e-f00622ed027c",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.001\n",
    "emission_counts, transition_counts, tag_counts = create_dictionaries(training_corpus, vocab)\n",
    "A = create_transition_matrix(alpha, tag_counts, transition_counts)\n",
    "B = create_emission_matrix(alpha, tag_counts, emission_counts, list(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323ee377-ea32-459a-b2fc-e1a90b8d422e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep = ['economy', 'what', '--unk--', 'run']\n",
    "best_probs, best_paths = initialize(states, tag_counts, A, B, prep, vocab)\n",
    "best_probs, best_paths = viterbi_forward(A, B, prep, best_probs, best_paths, vocab)\n",
    "pred = viterbi_backward(best_probs, best_paths, prep, states)\n",
    "#print(f\"Accuracy of the Viterbi algorithm is {compute_accuracy(pred, y):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9979cc24-b6fe-410a-9030-f42f8d598a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0517482e-159b-47e2-8ea1-3ca75bc0a9cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a367af7c-106b-4300-8ed4-f3a9928def08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575a0dd5-b621-4d6d-8db0-1a94a58ab4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
